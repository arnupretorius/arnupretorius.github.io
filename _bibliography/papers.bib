---
---

@article{pretoriusnoisy,
  title={Critical initialisation and deep signal propagation for noisy rectifier neural networks},
  author={Pretorius, A. and Van Biljon, E. and Kroon, S. and Kamper, H.},
  journal={In Advances of the 32nd Conference on Neural Information Processing Systems (NeurIPS),},
  year={2018},
  abstract={Stochastic regularisation is an important weapon in the arsenal of a deep learning practitioner. However, despite recent theoretical advances, our understanding of how noise influences signal propagation in deep neural networks remains limited. By extending recent work based on mean field theory, we develop a new framework for signal propagation in stochastic regularised neural networks. Our noisy signal propagation theory can incorporate several common noise distributions, including additive and multiplicative Gaussian noise as well as dropout. We use this framework to investigate initialisation strategies for noisy ReLU networks. We show that no critical initialisation strategy exists using additive noise, with signal propagation exploding regardless of the selected noise distribution. For multiplicative noise (e.g. dropout), we identify alternative critical initialisation strategies that depend on the second moment of the noise distribution. Simulations and experiments on real-world data confirm that our proposed initialisation is able to stably propagate signals in deep networks, while using an initialisation disregarding noise fails to do so. Furthermore, we analyse correlation dynamics between inputs. Stronger noise regularisation is shown to reduce the depth to which discriminatory information about the inputs to a noisy ReLU network is able to propagate, even when initialised at criticality. We support our theoretical predictions for these trainable depths with simulations, as well as with experiments on MNIST and CIFAR-10},
  arxiv={1811.00293},
  code={https://github.com/ElanVB/noisy_signal_prop},
}

@article{pretoriuslindyn,
  title={Learning Dynamics of Linear Denoising Autoencoders},
  author={Pretorius, A. and Kroon, S. and Kamper, H.},
  journal={In Proceedings of the 35th International Conference on
Machine Learning (ICML),},
  year={2018},
  abstract={Denoising autoencoders (DAEs) have proven useful for unsupervised representation learning, but a thorough theoretical understanding is still lacking of how the input noise influences learning. Here we develop theory for how noise influences learning in DAEs. By focusing on linear DAEs, we are able to derive analytic expressions that exactly describe their learning dynamics. We verify our theoretical predictions with simulations as well as experiments on MNIST and CIFAR-10. The theory illustrates how, when tuned correctly, noise allows DAEs to ignore low variance directions in the inputs while learning to reconstruct them. Furthermore, in a comparison of the learning dynamics of DAEs to standard regularised autoencoders, we show that noise has a similar regularisation effect to weight decay, but with faster training dynamics. We also show that our theoretical predictions approximate learning dynamics on real-world data and qualitatively match observed dynamics in nonlinear DAEs.},
  arxiv={1806.05413},
  code={https://github.com/arnupretorius/lindaedynamics_icml2018},
}

@article{pretoriusbiasvar,
  title={A Bias-Variance Analysis of Ensemble Learning
for Classification},
  author={Pretorius, A. and Bierman, S. and Steel, S.J.},
  journal={In Proceedings of the Annual Conference of the
South African Statistical Association (SASA),},
  year={2016},
  abstract={A decomposition of the expected prediction error into bias and variance components is useful when investigating the accuracy of a predictor. However, in classification such a decomposition is not as straightforward as in the case of squared-error loss in regression. As a result various definitions of bias and variance for classification can be found in the literature. In this paper these definitions are reviewed and an empirical study of a particular bias-variance decomposition is presented for ensemble classifiers.},
  html={https://journals.co.za/content/sasj_proc/2016/con-1/EJC198852?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3BI751iNLxTn%2BqB3Q6oh5vBQ%3D%3D#abstract_content},
  code={https://github.com/arnupretorius/BiasVarAnalEnsembleLearn},
}

@article{pretoriusmetarf,
  title={A Meta-Analysis of Research in Random Forests
for Classification},
  author={Pretorius, A. and Bierman, S. and Steel, S.J.},
  journal={In the Proceedings of the Annual Conference of the
Pattern Recognition Association of South Africa (PRASA),},
  year={2016},
  abstract={Since their introduction, random forests (RFs) have successfully been employed in a vast array of application areas. Fairly recently, a number of algorithms that are related to Breiman's original Forest-RI algorithm have been proposed in the literature. In this paper we conduct a meta-analysis of all (34) 2001-2015 papers that could be found in which a novel RF algorithm was proposed and compared to already established RF algorithms. The analysis revealed several limitations regarding the choice of performance measures, the way in which these measures are estimated, and the methodology for comparisons of multiple algorithms over multiple data sets. In fact, it is shown that in almost a third of the results from RF research papers, a significant improvement over the performance of Forest-RI is not found when comparisons are made using appropriate statistical tests.},
  html={http://ieeexplore.ieee.org/abstract/document/7813171/?reload=true&lipi=urn:li:page:d_flagship3_profile_view_base;I751iNLxTn%2BqB3Q6oh5vBQ%3D%3D},
  code={https://github.com/arnupretorius/RFResearchMetaAnalysis},
}

@article{pretoriussport,
  title={Human Decision Making and Artificial
Intelligence: A Comparison in the Domain of Sports Prediction},
  author={Pretorius, A. and Parry, D.},
  journal={In Proceedings of the Annual Conference of the South African Institute of
Computer Scientists and Information Technologists (SAICSIT),},
  year={2016},
  abstract={Artificial intelligence (AI) research has become prominent in both academia and industry. With this, an interest in AI's ability to make sound decisions when compared to human decision making has grown. Predicting the outcome of sporting events has traditionally been seen as a difficult task, due to the complex relationships between variables of interest. Attempts to make accurate predictions are fraught with biases owing to the bounded rationality within which human decision making functions. This study puts forward the position that an AI approach using machine learning will yield a comparable level of accuracy. A random forest classification algorithm was employed to predict match outcomes in the 2015 Rugby World Cup. The performance of this model was compared to aggregate results from Super-Bru and OddsPortal. The machine learning based system achieved an accuracy of 89.58% with 95%-CI (77.83, 95.47) vs. 85.42% with 95%-CI (72.83, 92.75) for the platforms. These results indicate that for rugby, over the limited period of a specific tournament, the evidence was not strong enough to suggest that a human agent is superior in terms of accuracy when predicting match outcomes compared to a machine learning approach, at a significance level Î± = 0.05. However, the model was better able to estimate probabilities as measured by monetary winnings from betting rounds compared to the two platforms.},
  html={https://dl.acm.org/citation.cfm?id=2987493&lipi=urn%253Ali%253Apage%253Ad_flagship3_profile_view_base%253BI751iNLxTn%252BqB3Q6oh5vBQ%253D%253D},
  code={https://github.com/arnupretorius/RWCPrediction},
}


